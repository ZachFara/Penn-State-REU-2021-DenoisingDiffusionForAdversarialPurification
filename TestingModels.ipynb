{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations: https://arxiv.org/abs/2006.11239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15136,
     "status": "ok",
     "timestamp": 1655495468198,
     "user": {
      "displayName": "Zach Farahany",
      "userId": "17909561336891020108"
     },
     "user_tz": 300
    },
    "id": "vefCF9ms8mCp",
    "outputId": "f8ac863e-55fc-42b1-a0ef-34e5efb93cd3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#!pip install foolbox;\n",
    "#!pip install torchattacks;\n",
    "#!pip install labml_nn;\n",
    "#!pip install datasets;\n",
    "#!pip install torchmetrics;\n",
    "#!pip install tqdm;\n",
    "#!pip install git+https://github.com/fra31/auto-attack;\n",
    "#!pip3 install torch==1.11.0+cu115 torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html;\n",
    "import os;\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\";\n",
    "import torch;\n",
    "torch.backends.cudnn.enabled = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_hip.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "from utils import *\n",
    "from UNet import *\n",
    "import torch\n",
    "import gc\n",
    "eps_model = load_eps_model()\n",
    "eps_model.eval();\n",
    "certified_denoiser = load_cert_denoiser()\n",
    "certified_denoiser.eval();\n",
    "acc = load_accuracy()\n",
    "resnet, resnet_scaled = load_resnet()\n",
    "x_train,y_train,x_test,y_test = load_data()\n",
    "set_random_seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from tqdm.notebook import tnrange\n",
    "from torch import nn\n",
    "import torch\n",
    "from typing import Tuple, Optional\n",
    "from labml_nn.diffusion.ddpm.utils import gather\n",
    "def check_t(self,t):\n",
    "    if t is None:\n",
    "        t = self.t\n",
    "    else: \n",
    "        t = torch.tensor([t]).to(device)\n",
    "    return t\n",
    "def check_MonteCarlo_iter(self,mc_iter):\n",
    "    if mc_iter is None:\n",
    "        mc_iter = 5\n",
    "    return mc_iter\n",
    "def check_spread(self,spread):\n",
    "    if spread is None:\n",
    "        spread = 5\n",
    "    return spread\n",
    "class DDPM():\n",
    "    def __init__(self,classifier,eps_model,t,num_classes = 10,batch_size = 2,grad = True):\n",
    "        self.classifier = classifier\n",
    "        self.num_classes = num_classes\n",
    "        self.eps_model = eps_model \n",
    "        self.n_steps = 5000\n",
    "        self.beta = torch.linspace(0.0001, 0.02, self.n_steps).to(device) #Noise scheduling, the beta t's \n",
    "        self.alpha = 1. - self.beta #Reparametarization trick to get at any timestep\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        self.sigma2 = self.beta\n",
    "        self.t = torch.tensor([t]).to(device)\n",
    "        self.acc = Accuracy(num_classes = self.num_classes).to(device)\n",
    "        self.batch_size = batch_size\n",
    "        self.grad = grad\n",
    "    def q_sample(self, x0: torch.Tensor, t: torch.Tensor, eps: Optional[torch.Tensor] = None): \n",
    "        if eps is None: #Create epsilon\n",
    "            eps = torch.randn_like(x0)  \n",
    "        mean, var = self.q_xt_x0(x0, t) #Get the mean and variance at this timestep\n",
    "        imgs = mean + (var ** 0.5)* eps\n",
    "        #Scale the images back to the same scale\n",
    "        return  imgs,eps\n",
    "    ##Forward process, now we sample from p which is the function that estimates xt-1 from xt\n",
    "    def p_sample(self, xt: torch.Tensor, t: torch.Tensor):\n",
    "        eps_theta = self.eps_model(xt, t) #Uses the model to predict the error\n",
    "        alpha_bar = gather(self.alpha_bar, t)\n",
    "        alpha = gather(self.alpha, t)\n",
    "        eps_coef = (1 - alpha) / (1 - alpha_bar) ** .5\n",
    "        mean = 1 / (alpha ** 0.5) * (xt - eps_coef * eps_theta)\n",
    "        var = gather(self.sigma2, t)\n",
    "        eps = torch.randn(xt.shape, device=xt.device)\n",
    "        return mean + (var ** 0.5) * eps #Returns a new sample\n",
    "    def denoise(self, xt: torch.Tensor, t: torch.Tensor):\n",
    "        num_iter = int(t)\n",
    "        for i in range(num_iter):\n",
    "            xt = self.p_sample(xt, t)\n",
    "            t -=1\n",
    "        return xt\n",
    "    def purify(self,x,t = None):\n",
    "        t = check_t(self,t)\n",
    "        if self.grad:\n",
    "            x_noise = self.q_sample(x,t)[0]\n",
    "            x_pure = self.denoise(x_noise,t)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                x_noise = self.q_sample(x,t)[0]\n",
    "                x_pure = self.denoise(x_noise,t)\n",
    "        return torch.clamp(x_pure,0,1)\n",
    "    def purify_batches(self,x,t = None):\n",
    "        t = check_t(self,t)\n",
    "        x_pure = torch.clone(x)\n",
    "        for i in range(0,len(x),self.batch_size):\n",
    "            x_pure[i:i+self.batch_size] = self.purify(x[i:i+self.batch_size],t)\n",
    "        return x_pure\n",
    "    def pytorch_model(self,x,t = None):\n",
    "        t = check_t(self,t)\n",
    "        #Make model such that foolbox can interact with it\n",
    "        purify_batches = self.purify_batches\n",
    "        class PurifyLayer(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "            def forward(self,x):\n",
    "                return purify_batches(x,t)\n",
    "        purify_layer = PurifyLayer()\n",
    "        model = nn.Sequential(\n",
    "        purify_layer,\n",
    "        resnet_scaled)\n",
    "        model.eval();\n",
    "        if self.grad:\n",
    "            return model(x)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return model(x)\n",
    "    def mc_predict(self,x,mc_iter = None, t = None):\n",
    "        t = check_t(self,t)\n",
    "        mc_iter = check_MonteCarlo_iter(self,mc_iter)\n",
    "        proba = torch.zeros((x.shape[0],self.num_classes)).to(device)\n",
    "        for i in tnrange(mc_iter):\n",
    "            proba += self.pytorch_model(x,t)\n",
    "        return proba/mc_iter\n",
    "    def spread_predict(self,x,mc_iter = None, t = None,spread_factor = None):\n",
    "        t = check_t(self,t)\n",
    "        mc_iter = check_MonteCarlo_iter(self,mc_iter)\n",
    "        spread_factor = check_spread(self,spread_factor)\n",
    "        proba = torch.zeros((x.shape[0],self.num_classes)).to(device)\n",
    "        for i in tnrange(mc_iter):\n",
    "            _t_ = (t - (mc_iter // 2)*spread_factor) + i*spread_factor\n",
    "            print(\"Using t = \"+ str(float(_t_)), end = \"\\r\")\n",
    "            proba += self.pytorch_model(x,_t_)\n",
    "        return proba/mc_iter\n",
    "    def eval_normal(self,x,y, t = None):\n",
    "        proba = self.pytorch_model(x,t)\n",
    "        return float(self.acc(proba,y))*100\n",
    "    def eval_montecarlo(self,x,y,mc_iter = None, t = None):\n",
    "        proba = self.mc_predict(x,mc_iter,t)\n",
    "        return float(self.acc(proba,y))*100\n",
    "    def eval_spread(self,x,y,mc_iter = None, t = None,spread_factor = None):\n",
    "        proba = self.spread_predict(x,mc_iter,t,spread_factor)\n",
    "        return float(self.acc(proba,y))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import catch_warnings,simplefilter\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "def surrogate(model, x):\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")\n",
    "    return model.predict(x, return_std=True)\n",
    "\n",
    "def opt_acquisition(x, y, model,high,low):\n",
    "    # random search, generate random samples\n",
    "    xsamples = np.random.randint(low,high,(high-low))\n",
    "    xsamples = xsamples.reshape(len(xsamples), 1)\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(x, xsamples, model)\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    return xsamples[ix, 0]\n",
    "\n",
    "from scipy.stats import norm\n",
    "# probability of improvement acquisition function\n",
    "def acquisition(X, Xsamples, model):\n",
    "    # calculate the best surrogate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best = max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "    mu = mu[:, 0]\n",
    "    # calculate the probability of improvement\n",
    "    probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "    return probs\n",
    "\n",
    "def bayes_opt(x,y,high,low):\n",
    "    x_ = np.array(x)\n",
    "    y_ = np.array(y)\n",
    "    #x_ = x\n",
    "    #y_ = y\n",
    "    model = GaussianProcessRegressor()\n",
    "    model.fit(x_.reshape(-1, 1),y_.reshape(-1, 1))\n",
    "    return torch.tensor([opt_acquisition(x_.reshape(-1, 1),y_.reshape(-1, 1),model,high,low)]).numpy(), model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labml_nn.diffusion.ddpm.utils import gather\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "from scipy.stats import norm\n",
    "import statsmodels\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "def check_class_argument(self,arg,attrib):\n",
    "    if arg is None:\n",
    "        return getattr(self, attrib)\n",
    "    else:\n",
    "        return arg\n",
    "class CertifiedRobustnessModel():\n",
    "    def __init__(self,classifier,denoise_model,t,num_classes = 10,batch_size = 2,num_iter = 10, grad = True):\n",
    "        self.classifier = classifier\n",
    "        self.denoise_model = denoise_model\n",
    "        self.t = torch.tensor([t]).to(device).long()\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_iter = num_iter\n",
    "        self.grad = grad\n",
    "        self.acc = Accuracy(num_classes = self.num_classes).to(device)\n",
    "        self.beta = torch.linspace(0.0001, 0.02, 5000).to(device) #Noise scheduling, the beta t's \n",
    "        self.alpha = 1. - self.beta #Reparametarization trick to get at any timestep\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "    def forward_sample(self,x,t = None):\n",
    "        t = check_t(self,t)\n",
    "        #torch.manual_seed(torch.seed())\n",
    "        sigma2 = (1 - self.alpha_bar[t])/self.alpha_bar[t]\n",
    "        delta = torch.randn(x.shape).to(device) * sigma2\n",
    "        return self.alpha_bar[t]**0.5 * x + delta\n",
    "    def backward_sample(self,x,t = None):\n",
    "        t = check_t(self,t)\n",
    "        return self.denoise_model(x,t)\n",
    "    def purify_batch(self,x,t = None):\n",
    "        t = check_t(self,t)\n",
    "        if self.grad:\n",
    "            x_pure = torch.clone(x)\n",
    "            for i in range(0,len(x),self.batch_size):\n",
    "                x_noise = self.forward_sample(x[i:i+self.batch_size],t)\n",
    "                x_pure[i:i+self.batch_size] = self.backward_sample(x_noise,t)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                x_pure = torch.clone(x)\n",
    "                for i in range(0,len(x),self.batch_size):\n",
    "                    x_noise = self.forward_sample(x[i:i+self.batch_size],t)\n",
    "                    x_pure[i:i+self.batch_size] = self.backward_sample(x_noise,t)\n",
    "        return x_pure\n",
    "    def pred_batch(self,x,batch_size):\n",
    "        logits = torch.empty(len(x),self.num_classes)\n",
    "        if self.grad:\n",
    "            for i in range(0,len(x),batch_size):\n",
    "                logits[i:i+batch_size] = self.classifier(x[i:i+batch_size])\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                for i in range(0,len(x),batch_size):\n",
    "                    logits[i:i+batch_size] = self.classifier(x[i:i+batch_size])  \n",
    "        return logits\n",
    "    #Num iter is supposed to be 100_000\n",
    "    def algo_1(self,x,num_iter = None,t = None):\n",
    "        t = check_t(self,t)\n",
    "        num_iter = check_class_argument(self,num_iter,'num_iter')\n",
    "        preds = torch.zeros(size = (len(x),self.num_classes)).to(device)\n",
    "        for i in tnrange(num_iter):\n",
    "            x_pure = self.purify_batch(x,t)\n",
    "            logits = self.pred_batch(x_pure,100)\n",
    "            classes_predicted = torch.argmax(logits,dim = 1)\n",
    "            for i,class_ in enumerate(classes_predicted):\n",
    "                preds[i,class_] += 1\n",
    "        return (preds.float()/num_iter)\n",
    "    def spread(self,x,num_iter = None,t = None, mc_iter = None, spread_factor = None):\n",
    "        t = check_t(self,t)\n",
    "        mc_iter = check_MonteCarlo_iter(self,mc_iter)\n",
    "        spread_factor = check_spread(self,spread_factor)\n",
    "        proba = torch.zeros((x.shape[0],self.num_classes)).to(device)\n",
    "        for i in tnrange(mc_iter):\n",
    "            _t_ = (t - (mc_iter // 2)*spread_factor) + i*spread_factor\n",
    "            print(\"Using t = \"+ str(float(_t_)), end = \"\\r\")\n",
    "            proba += self.algo_1(x,t = _t_)\n",
    "        return proba/mc_iter\n",
    "    def eval_(self,x,y,t = None,num_iter = None):\n",
    "        t = check_t(self,t)\n",
    "        num_iter = check_class_argument(self,num_iter,'num_iter')\n",
    "        proba = self.algo_1(x,t = t,num_iter = num_iter)\n",
    "        return float(self.acc(proba,y))*100\n",
    "    def certify(self,x, n0 = 100, n = 1_000_000, alpha = .05, t = None):\n",
    "        t = check_t(self,t)\n",
    "        counts0 = self.algo_1(x,num_iter = n0, t = t) * n0\n",
    "        ca = counts0.topk(1)[1].flatten()\n",
    "        counts = self.algo_1(x,num_iter = n, t = t) * n\n",
    "        top_ix = torch.empty(len(x))\n",
    "        for i in range(len(top_ix)):\n",
    "            top_ix[i] = counts[i,ca[i]]\n",
    "        pa = proportion_confint(top_ix.cpu(),n,alpha = 2*(1-alpha),method = \"beta\")[0]\n",
    "        sigma = ((1 - self.alpha_bar[t])/self.alpha_bar[t])**.5\n",
    "        radius = sigma.cpu() * norm.ppf(pa)\n",
    "        return ca, radius\n",
    "    def gaussian_process(self,x,y,high,low,initial_points = 5,batch_size = 100, mc_iter = 100):\n",
    "        ts = list()\n",
    "        scores = list()\n",
    "        preds = torch.zeros(size = (len(x),self.num_classes)).to(device)\n",
    "        #Sample the random initial points\n",
    "        for j in range(initial_points):\n",
    "            curr_t = torch.randint(low = low, high = high,size = [1]).numpy()[0]\n",
    "            ts.append(curr_t)\n",
    "            x_pure = self.purify_batch(x,t = curr_t)\n",
    "            logits = self.pred_batch(x_pure,batch_size)\n",
    "            scores.append(self.acc(logits.to(device),y.to(device)))\n",
    "            classes_predicted = torch.argmax(logits,dim = 1)\n",
    "            for z,class_ in enumerate(classes_predicted):\n",
    "                preds[z,class_] += 1\n",
    "        #Now use the Gaussian process\n",
    "        for j in range(initial_points,mc_iter):\n",
    "            curr_t,model = bayes_opt(ts,scores,high,low)\n",
    "            curr_t = curr_t[0]\n",
    "            ts.append(curr_t)\n",
    "            print(\"Currently trying t = \"+ str(curr_t), end = \"\\r\")\n",
    "            x_pure = self.purify_batch(x,t = curr_t)\n",
    "            logits = self.pred_batch(x_pure,batch_size)\n",
    "            scores.append(self.acc(logits.to(device),y.to(device)) )         \n",
    "            classes_predicted = torch.argmax(logits,dim = 1)\n",
    "            for z,class_ in enumerate(classes_predicted):\n",
    "                preds[z,class_] += 1\n",
    "        return preds,np.mean(ts)\n",
    "    def gauss_batch(self,x,y,high,low,initial_points = 10,batch_size = 1, mc_iter = 100):\n",
    "        ts = torch.empty(len(x)).to(device)\n",
    "        preds = torch.zeros(size = (len(x),self.num_classes)).to(device)\n",
    "        for i in tnrange(0,len(x),batch_size):\n",
    "            preds[i:i+batch_size], ts[i:i+batch_size] = self.gaussian_process(x[i:i+batch_size],y[i:i+batch_size],\n",
    "                                                          high,low,initial_points = initial_points,\n",
    "                                                          batch_size = 100, mc_iter = mc_iter)\n",
    "        return preds, ts\n",
    "    def random_t(self,x,high,low,mc_iter = 100):\n",
    "        ts = torch.empty(mc_iter).to(device)\n",
    "        preds = torch.zeros(size = (len(x),self.num_classes)).to(device)\n",
    "        for j in tnrange(mc_iter):\n",
    "            curr_t = torch.randint(low = low, high = high,size = [1]).numpy()[0]\n",
    "            ts[j] = curr_t\n",
    "            x_pure = self.purify_batch(x,t = curr_t)\n",
    "            logits = self.pred_batch(x_pure,100)\n",
    "            classes_predicted = torch.argmax(logits,dim = 1)\n",
    "            for z,class_ in enumerate(classes_predicted):\n",
    "                preds[z,class_] += 1\n",
    "        t_s = torch.ones(len(x)).to(device)* ts.float().mean()\n",
    "        return preds, t_s\n",
    "    def random_t_batch(self,x,high,low,mc_iter = 100,batch_size = 100):\n",
    "        preds = torch.zeros(size = (len(x),self.num_classes)).to(device)\n",
    "        ts = torch.zeros(len(x))\n",
    "        for i in range(0,len(x),batch_size):\n",
    "            preds[i:i+batch_size],ts[i:i+batch_size] = self.random_t(x[i:i+batch_size],\n",
    "                                                          high,low,mc_iter = mc_iter)\n",
    "        return preds,ts\n",
    "    def certify_gauss(self,x,y,n0 = 100, n = 1_000_000, alpha = .05):\n",
    "        counts0,_ = self.gauss_batch(x,y,400,10,initial_points = int(n0/10),mc_iter = n0,batch_size = 1)\n",
    "        ca = counts0.topk(1)[1].flatten()\n",
    "        counts,ts = self.gauss_batch(x,y,400,10,initial_points = int(n/10),mc_iter = n,batch_size = 1)\n",
    "        t1 = torch.round(ts.mean()).long().to(device)\n",
    "        print(t1)\n",
    "        top_ix = torch.empty(len(x))\n",
    "        for i in range(len(top_ix)):\n",
    "            top_ix[i] = counts[i,ca[i]]\n",
    "        pa = proportion_confint(top_ix.cpu(),n,alpha = 2*(1-alpha),method = \"beta\")[0]\n",
    "        sigma = ((1 - self.alpha_bar[t1])/self.alpha_bar[t1])**.5\n",
    "        radius = sigma.cpu() * norm.ppf(pa)\n",
    "        return ca, radius\n",
    "    def certify_rand(self,x,n0 = 100, n = 1_000_000, alpha = .05):\n",
    "        counts0,_ = self.random_t_batch(x,400,10,mc_iter = n0)\n",
    "        ca = counts0.topk(1)[1].flatten()\n",
    "        counts,ts = self.random_t_batch(x,400,10,mc_iter = n)\n",
    "        t1 = torch.round(ts.mean()).long().to(device)\n",
    "        print(t1)\n",
    "        top_ix = torch.empty(len(x))\n",
    "        for i in range(len(top_ix)):\n",
    "            top_ix[i] = counts[i,ca[i]]\n",
    "        pa = proportion_confint(top_ix.cpu(),n,alpha = 2*(1-alpha),method = \"beta\")[0]\n",
    "        sigma = ((1 - self.alpha_bar[t1])/self.alpha_bar[t1])**.5\n",
    "        radius = sigma.cpu() * norm.ppf(pa)\n",
    "        return ca, radius\n",
    "    def eval_spread(self,x,y,t = None,num_iter = None, mc_iter = None, spread_factor = None):\n",
    "        t = check_t(self,t)\n",
    "        mc_iter = check_MonteCarlo_iter(self,mc_iter)\n",
    "        spread_factor = check_spread(self,spread_factor)\n",
    "        proba = self.spread(x,t = t, num_iter = num_iter, mc_iter = mc_iter,spread_factor = spread_factor)\n",
    "        return float(self.acc(proba,y))*100\n",
    "    def exhaustive_t_search(self,x,y,high,low,batch_size):\n",
    "        results = dict()\n",
    "        ts = np.arange(low,high,20)\n",
    "        for i,t in tqdm(enumerate(ts),total = len(ts)):\n",
    "            results[t] = self.eval_(x[0:batch_size],y[0:batch_size], t = torch.tensor([t]).to(device))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all the models to test\n",
    "ddpm = DDPM(resnet_scaled,eps_model,100,grad = False)\n",
    "crm = CertifiedRobustnessModel(resnet_scaled,certified_denoiser,100,grad = False)\n",
    "x_adv = load_x_adv('PGDL2 vs resnet','pgdl2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154e948cac144c6c90c1a7dca4e23b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 994\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'numel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4188/3276188903.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgauss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_full_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_reduce_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36m_forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# calculate batch state and compute batch value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected all tensors to be on\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[1;32m    218\u001b[0m         \u001b[0;34m\"\"\" returns the mode of the data (binary, multi label, multi class, multi-dim multi class) \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36m_mode\u001b[0;34m(preds, target, threshold, top_k, num_classes, multiclass, ignore_index)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     mode = _check_classification_inputs(\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, multiclass, top_k, ignore_index)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;31m# Basic validation (that does not need case/type information)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0m_basic_input_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Check that shape/types fall into one of the cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_basic_input_validation\u001b[0;34m(preds, target, threshold, multiclass, ignore_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"\"\"Perform basic validation of inputs that does not require deducing any information of the type of inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Skip all other checks if both preds and target are empty tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_check_for_empty_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_check_for_empty_tensors\u001b[0;34m(preds, target)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_for_empty_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'numel'"
     ]
    }
   ],
   "source": [
    "logits = crm.gauss_batch(x_adv[0:1000],y_test[0:1000],400,10,batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8490, device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crm.acc(logits[0],y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6d2ccf9bd547dbaf2a3d564c917bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 130\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7890, device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits,ts = crm.gauss_batch(x_adv[0:1000],y_test[0:1000],400,10,batch_size = 10)\n",
    "crm.acc(logits,y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407d89bb115f434286208c01d31e6075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 157\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90aa839ba324e02a64f01481738daed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 103\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c4c2464fe74a2bb088c4783054ca1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 148\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ed310dbb234698bd4ae59d3b61df48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 130\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0954c6d067ef473ebe6f3afb68714197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 121\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cac4ec6df84af290fb2129c491c2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 526\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a37f147c1a4e2b8e803149de74bc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 126\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c4fd0ca6084deabb472a6d629267f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 153\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95507052afc4f39961ffb6efc241e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 406\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75cc6db8eeb44fdad9664988fea52ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying t = 260\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7710, device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = crm.gauss_batch(x_adv[0:1000],y_test[0:1000],400,10)\n",
    "crm.acc(logits,y_test[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Compare fixed t vs randomized sampling versus bayesian\n",
    "-Prepare results on the radius\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14852accb1f04fd6ac607375308a3d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7690, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = crm.algo_1(x_adv[0:1000],num_iter = 100, t = 120)\n",
    "crm.acc(logits,y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13949d7eb9bd497d913685a80ca4c0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784a79dd65a641eca4e33762f21a8278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, radii = crm.certify(x_adv[0:100], n0 = 100, n = 3_000, alpha = .05, t = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7700, device='cuda:0')\n",
      "tensor(0.5327, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(crm.acc(preds,y_test[0:100]))\n",
    "print(torch.mean(radii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa938d2e3d54890ab4b8a42c197b671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e3dc448b69450ca92f97aef2446cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(204, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preds2, radii2 = crm.certify_rand(x_adv[0:100], n0 = 100, n = 3_000, alpha = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7600, device='cuda:0')\n",
      "tensor(0.2181, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(crm.acc(preds2,y_test[0:100]))\n",
    "print(torch.mean(radii2))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPiE9rPdXGWgAiJNsukzJVf",
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Full_Pipeline.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('psu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1028fe41cec8654ebc71273de4774acc5bc526b98fa48d7193f02b81eae34220"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b6e98f8c0764b78800cb334620a11b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "240923ea1ec64badad20a3bb0eb29471": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af65150131a9433ebf8a829347e9ff1a",
      "placeholder": "​",
      "style": "IPY_MODEL_70b1906ff10443788e6d7cb5d3c9c97e",
      "value": " 5/5 [00:05&lt;00:00,  1.03s/it]"
     }
    },
    "24cd3f6a1add4a5da808e682e548564e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e83efda50f8746b48c2689637f9cc67d",
       "IPY_MODEL_4531ef306f7342ce8ff08427234bdece",
       "IPY_MODEL_240923ea1ec64badad20a3bb0eb29471"
      ],
      "layout": "IPY_MODEL_432db219e06949cd984b680af118f86e"
     }
    },
    "432db219e06949cd984b680af118f86e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4531ef306f7342ce8ff08427234bdece": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b6e98f8c0764b78800cb334620a11b4",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d9b08a0df9784ae7810b550cd8adaf10",
      "value": 5
     }
    },
    "70b1906ff10443788e6d7cb5d3c9c97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af65150131a9433ebf8a829347e9ff1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0288d33f79245e48ba25316eb37ab86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c037c8389be242c0a620619c9ac4a172": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9b08a0df9784ae7810b550cd8adaf10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e83efda50f8746b48c2689637f9cc67d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c037c8389be242c0a620619c9ac4a172",
      "placeholder": "​",
      "style": "IPY_MODEL_c0288d33f79245e48ba25316eb37ab86",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
